# -*- coding: utf-8 -*-
"""udacity_scrapp

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19C--8lNAsObhujlfd8LNk08ejre2uyRh
"""

from bs4 import BeautifulSoup
import requests

response = requests.get("https://www.udacity.com/courses/all")
html_soup = BeautifulSoup(response.content, 'html.parser')

#find all the URLs (items in the html where href exists)
url = html_soup.find_all(href=True)

def auto_Scrapper_Class(html_tag,course_case,tag_class):
  for i in range(0,20):
    url = "https://www.udacity.com/courses/all"
    page = requests.get(url)
    soup = BeautifulSoup(page.content, 'html.parser')
    x = soup.find_all(html_tag, class_ = tag_class)[i].get_text()
    course_case.append(x)

def auto_Scrapper_Class_url(html_tag,course_case,tag_class):
  for i in range(0,20):
    url = "https://www.udacity.com/courses/all"
    page = requests.get(url)
    soup = BeautifulSoup(page.content, 'html.parser')
    x = soup.find_all(html_tag, class_ = tag_class)[i].get_text()
    courses_url.append("https://www.udacity.com/course" + a['href'])

course_title = []
course_organization = []
course_Certificate_type = []
course_difficulty = []
courses_url = []


auto_Scrapper_Class('a',course_title,'capitalize')
auto_Scrapper_Class('span',course_difficulty,'capitalize')
auto_Scrapper_Class('h4',course_organization,'category ng-star-inserted')
auto_Scrapper_Class('span',course_Certificate_type,'tag tag--free card ng-star-inserted')
auto_Scrapper_Class_url('a',courses_url,'capitalize')

import pandas as pd
courses_df = pd.DataFrame({'course_title': course_title,
                          'course_organization': course_organization,
                          'course_Certificate_type': course_Certificate_type,
                          'courses_url':courses_url,
                           'course_difficulty':course_difficulty})
courses_df = courses_df.sort_values('course_title')
print(courses_df.info())
courses_df.head()

courses_df.to_csv('udacity_Courses.csv')

